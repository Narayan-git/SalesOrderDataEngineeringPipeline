{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2074380e-c0e3-453e-b0f6-3bc2447fa7ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üì¶ Order Fact Table - Full Load Processing\n",
    "\n",
    "## üéØ Purpose\n",
    "Transform raw order data through the Medallion Architecture (Bronze ‚Üí Silver ‚Üí Gold) with aggregation to monthly grain, then merge with parent company fact table.\n",
    "\n",
    "## üìä Pipeline Overview\n",
    "\n",
    "| Layer | Purpose | Key Operations |\n",
    "|-------|---------|-----------------|\n",
    "| **Bronze** | Raw order ingestion | Load CSV, add metadata, append |\n",
    "| **Silver** | Clean & deduplicate | Parse dates, validate IDs, remove duplicates, join products |\n",
    "| **Gold** | Monthly aggregation | Group by month, sum quantities, merge to parent |\n",
    "\n",
    "## üîë Input & Output Tables\n",
    "\n",
    "**Inputs:**\n",
    "- `orders/landing/*.csv` - Raw order files from ADLS\n",
    "\n",
    "**Outputs:**\n",
    "- `fmcg.bronze.orders` - Raw orders with metadata\n",
    "- `fmcg.silver.orders` - Cleaned orders with product joins\n",
    "- `fmcg.gold.sb_fact_orders` - SportsBar monthly aggregates\n",
    "- `fmcg.gold.fact_orders` - Parent company fact table (merged)\n",
    "\n",
    "## üìã Key Transformations\n",
    "‚úÖ **Multi-format Date Parsing:** Handles multiple date formats automatically  \n",
    "‚úÖ **Customer ID Validation:** Numeric check, default invalid to 999999  \n",
    "‚úÖ **Deduplication:** Remove duplicate order records  \n",
    "‚úÖ **Product Joining:** Integrate product master data  \n",
    "‚úÖ **Monthly Aggregation:** Transform daily ‚Üí monthly grain  \n",
    "‚úÖ **File Management:** Archive processed files after success\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df881c02-1262-49ab-80e6-f3cf4493990c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORT REQUIRED LIBRARIES\n",
    "# ============================================================================\n",
    "# PySpark functions for data transformation and Delta Lake merge operations\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# ============================================================================\n",
    "# LIBRARY USAGE:\n",
    "# - F: String processing, date parsing, aggregation functions\n",
    "# - DeltaTable: MERGE operations for incremental/full loads\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b79c320-acee-472b-bd54-13277225104a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORT SHARED CONFIGURATION\n",
    "# ============================================================================\n",
    "# Load schema names and configuration from setup utilities\n",
    "# This ensures consistency across all notebooks\n",
    "\n",
    "# %run /Workspace/Project1/1_setup_catalog/utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "014597fe-1699-4c7a-9965-d95a47fc6653",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bronze silver gold\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VERIFICATION: Print imported schema names\n",
    "# ============================================================================\n",
    "# Confirms utilities were successfully imported\n",
    "# Expected output: bronze silver gold\n",
    "\n",
    "print(bronze_schema, silver_schema, gold_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5180c7c2-956e-4bbf-b7dc-ebb4b29ac59a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Path:  abfss://conatiner-de-practice@adlsgen2narayan.dfs.core.windows.net/orders\n",
      "Landing Path:  abfss://conatiner-de-practice@adlsgen2narayan.dfs.core.windows.net/orders/landing/\n",
      "Processed Path:  abfss://conatiner-de-practice@adlsgen2narayan.dfs.core.windows.net/orders/processed/\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURE DATABRICKS WIDGETS & PATHS\n",
    "# ============================================================================\n",
    "# Define parameters and storage paths for order processing\n",
    "\n",
    "dbutils.widgets.text(\"catalog\", \"fmcg\", \"Catalog\")\n",
    "dbutils.widgets.text(\"data_source\", \"orders\", \"Data Source\")\n",
    "\n",
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "data_source = dbutils.widgets.get(\"data_source\")\n",
    "\n",
    "# ============================================================================\n",
    "# DEFINE ADLS GEN2 PATHS\n",
    "# ============================================================================\n",
    "# Path structure for orders:\n",
    "# - landing: Incoming CSV files waiting to be processed\n",
    "# - processed: Files that have been successfully loaded (archive)\n",
    "\n",
    "base_path = f\"abfss://conatiner-de-practice@adlsgen2narayan.dfs.core.windows.net/{data_source}\"\n",
    "landing_path = f\"{base_path}/landing/\"\n",
    "processed_path = f\"{base_path}/processed/\"\n",
    "\n",
    "print(\"Base Path: \", base_path)\n",
    "print(\"Landing Path: \", landing_path)\n",
    "print(\"Processed Path: \", processed_path)\n",
    "\n",
    "# ============================================================================\n",
    "# DEFINE TABLE NAMES\n",
    "# ============================================================================\n",
    "# Fully qualified table names (catalog.schema.table)\n",
    "\n",
    "bronze_table = f\"{catalog}.{bronze_schema}.{data_source}\"\n",
    "silver_table = f\"{catalog}.{silver_schema}.{data_source}\"\n",
    "gold_table = f\"{catalog}.{gold_schema}.sb_fact_{data_source}\"\n",
    "\n",
    "print(\"Bronze Table: \", bronze_table)\n",
    "print(\"Silver Table: \", silver_table)\n",
    "print(\"Gold Table: \", gold_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7521eee0-90aa-4c36-bdc7-968e31836ea8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üü† BRONZE LAYER - Raw Order Ingestion\n",
    "\n",
    "**Purpose:** Load raw order data from ADLS with minimal transformation  \n",
    "**Update Pattern:** Append mode (add new records)  \n",
    "**Key Characteristics:** Full lineage with metadata, Change Data Feed enabled\n",
    "\n",
    "### Process:\n",
    "1. Read CSV files from landing directory\n",
    "2. Add metadata (timestamp, file name, file size)\n",
    "3. Append to Bronze table (preserves historical data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b1d3fd1-2cc6-4366-99f9-2b44369c8571",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows:  51810\n",
      "+------------+--------------------+-----------+----------+---------+--------------------+--------------------+---------+\n",
      "|    order_id|order_placement_date|customer_id|product_id|order_qty|      read_timestamp|           file_name|file_size|\n",
      "+------------+--------------------+-----------+----------+---------+--------------------+--------------------+---------+\n",
      "|FOCT62720602|Tuesday, Septembe...|     ABC987|  25891301|     71.0|2025-11-30 15:21:...|orders_2025_09_30...|    41446|\n",
      "|FOCT62720602|Tuesday, Septembe...|     789720|  25891502|    125.0|2025-11-30 15:21:...|orders_2025_09_30...|    41446|\n",
      "|FOCT62720602|Tuesday, Septembe...|     789720|  25891403|    462.0|2025-11-30 15:21:...|orders_2025_09_30...|    41446|\n",
      "|FOCT62720602|Tuesday, Septembe...|    INVALID|  25891601|    133.0|2025-11-30 15:21:...|orders_2025_09_30...|    41446|\n",
      "|FOCT62720602|Tuesday, Septembe...|     789720|  25891602|     79.0|2025-11-30 15:21:...|orders_2025_09_30...|    41446|\n",
      "+------------+--------------------+-----------+----------+---------+--------------------+--------------------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# BRONZE LAYER: READ RAW ORDER DATA\n",
    "# ============================================================================\n",
    "# Load CSV files from landing directory with metadata tracking\n",
    "\n",
    "df = spark.read.options(header=True, inferSchema=True).csv(f\"{landing_path}/*.csv\")\\\n",
    "    .withColumn(\"read_timestamp\", F.current_timestamp())\\\n",
    "    .select(\"*\", \"_metadata.file_name\", \"_metadata.file_size\")\n",
    "\n",
    "print(\"Total Rows: \", df.count())\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a31a89a-3a43-4b3c-b166-0c610be5990e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# BRONZE LAYER: APPEND TO DELTA TABLE\n",
    "# ============================================================================\n",
    "# Persist raw orders to Bronze layer\n",
    "# Mode: APPEND (preserve historical data across runs)\n",
    "\n",
    "df.write\\\n",
    " .format(\"delta\") \\\n",
    " .option(\"delta.enableChangeDataFeed\", \"true\") \\\n",
    " .mode(\"append\") \\\n",
    " .saveAsTable(bronze_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5424987a-817b-4d56-879f-8c6abd173ad1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìÅ File Management - Archive Processed Files\n",
    "\n",
    "**Purpose:** Prevent reprocessing of same files in future runs  \n",
    "**Method:** Move files from landing ‚Üí processed directory  \n",
    "**Benefit:** Audit trail and data lineage tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1fda72e-572f-468d-a32f-0890579e3af6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FILE ARCHIVAL: Move processed files to archive directory\n",
    "# ============================================================================\n",
    "# After successful processing, move files from landing to processed directory\n",
    "# This prevents accidental reprocessing and maintains data lineage\n",
    "#\n",
    "# Logic:\n",
    "# 1. List all files in landing directory\n",
    "# 2. For each file, move to processed directory\n",
    "# 3. Third parameter (True) forces overwrite if file exists\n",
    "# ============================================================================\n",
    "\n",
    "files = dbutils.fs.ls(landing_path)\n",
    "for file_info in files:\n",
    "    dbutils.fs.mv(\n",
    "        file_info.path,\n",
    "        f\"{processed_path}/{file_info.name}\",\n",
    "        True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd86ba92-9daa-4876-85b5-2456534eb845",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üü° SILVER LAYER - Data Cleaning & Standardization\n",
    "\n",
    "**Purpose:** Create clean, validated orders ready for analysis  \n",
    "**Update Pattern:** MERGE (upsert)  \n",
    "**Key Operations:**\n",
    "- ‚úÖ Filter non-null order quantities\n",
    "- ‚úÖ Validate and sanitize customer IDs\n",
    "- ‚úÖ Parse dates in multiple formats\n",
    "- ‚úÖ Remove duplicate orders\n",
    "- ‚úÖ Join with product master data\n",
    "\n",
    "### Data Quality Steps:\n",
    "1. Load Bronze orders\n",
    "2. Validate order quantities (non-null)\n",
    "3. Clean customer IDs (numeric check)\n",
    "4. Parse dates (4 formats supported)\n",
    "5. Remove duplicates\n",
    "6. Join with products\n",
    "7. Merge to Silver table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "316ebc28-f6b4-4a61-bbd1-22d8f8cb1280",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------+----------+---------+--------------------+--------------------+---------+\n",
      "|    order_id|order_placement_date|customer_id|product_id|order_qty|      read_timestamp|           file_name|file_size|\n",
      "+------------+--------------------+-----------+----------+---------+--------------------+--------------------+---------+\n",
      "|FJUL33320501|          2025/07/01|     789320|  25891203|    150.0|2025-11-30 15:23:...|orders_2025_07_01...|    20744|\n",
      "|FJUL33320501|          2025/07/01|     789320|  25891301|     46.0|2025-11-30 15:23:...|orders_2025_07_01...|    20744|\n",
      "+------------+--------------------+-----------+----------+---------+--------------------+--------------------+---------+\n",
      "only showing top 2 rows\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SILVER LAYER: LOAD DATA FROM BRONZE\n",
    "# ============================================================================\n",
    "# Read raw orders from Bronze layer for transformation\n",
    "\n",
    "df_orders = spark.sql(f\"SELECT * FROM {bronze_table}\")\n",
    "df_orders.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab61e408-086c-4476-8544-8d7b9018e5ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üîÑ Silver Layer Transformations\n",
    "\n",
    "Apply data quality and standardization rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4fed5ae-edaa-4460-b295-3d03ba799f27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATA QUALITY STEP 1: VALIDATE ORDER QUANTITIES\n",
    "# ============================================================================\n",
    "# Business Rule: Only process orders with non-null quantities\n",
    "# Impact: Removes invalid/incomplete orders\n",
    "\n",
    "df_orders = df_orders.filter(F.col(\"order_qty\").isNotNull())\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# DATA QUALITY STEP 2: CLEAN CUSTOMER ID\n",
    "# ============================================================================\n",
    "# Problem: Some customer IDs may be invalid/non-numeric\n",
    "# Solution: Keep numeric IDs, set invalid ones to 999999 (error code)\n",
    "# This enables tracking of problematic records while maintaining continuity\n",
    "\n",
    "df_orders = df_orders.withColumn(\n",
    "    \"customer_id\",\n",
    "    F.when(F.col(\"customer_id\").rlike(\"^[0-9]+$\"), F.col(\"customer_id\"))\n",
    "     .otherwise(\"999999\")\n",
    "     .cast(\"string\")\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# DATA QUALITY STEP 3: PARSE DATE - REMOVE WEEKDAY PREFIX\n",
    "# ============================================================================\n",
    "# Problem: Some dates have weekday prefix (e.g., \"Tuesday, July 01, 2025\")\n",
    "# Solution: Remove weekday and comma using regex\n",
    "# Result: \"July 01, 2025\" ready for parsing\n",
    "\n",
    "df_orders = df_orders.withColumn(\n",
    "    \"order_placement_date\",\n",
    "    F.regexp_replace(F.col(\"order_placement_date\"), r\"^[A-Za-z]+,\\s*\", \"\")\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# DATA QUALITY STEP 4: PARSE DATE - MULTI-FORMAT SUPPORT\n",
    "# ============================================================================\n",
    "# Problem: Dates come in multiple formats from different sources\n",
    "# Solution: Try multiple formats with coalesce fallback\n",
    "# \n",
    "# Supported Formats:\n",
    "# 1. yyyy/MM/dd (2025-01-15)\n",
    "# 2. dd-MM-yyyy (15-01-2025)  \n",
    "# 3. dd/MM/yyyy (15/01/2025)\n",
    "# 4. MMMM dd, yyyy (January 15, 2025)\n",
    "#\n",
    "# coalesce returns first non-NULL result\n",
    "\n",
    "df_orders = df_orders.withColumn(\n",
    "    \"order_placement_date\",\n",
    "    F.coalesce(\n",
    "        F.try_to_date(\"order_placement_date\", \"yyyy/MM/dd\"),\n",
    "        F.try_to_date(\"order_placement_date\", \"dd-MM-yyyy\"),\n",
    "        F.try_to_date(\"order_placement_date\", \"dd/MM/yyyy\"),\n",
    "        F.try_to_date(\"order_placement_date\", \"MMMM dd, yyyy\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# DATA QUALITY STEP 5: REMOVE DUPLICATE ORDERS\n",
    "# ============================================================================\n",
    "# Business Rule: Each order should be unique by (order_id, date, customer, product, qty)\n",
    "# Deduplication prevents double-counting in aggregations\n",
    "\n",
    "df_orders = df_orders.dropDuplicates(\n",
    "    [\"order_id\", \"order_placement_date\", \"customer_id\", \"product_id\", \"order_qty\"]\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# DATA QUALITY STEP 6: CONVERT PRODUCT ID TO STRING\n",
    "# ============================================================================\n",
    "# Standardize product_id type for consistent joins with product master\n",
    "\n",
    "df_orders = df_orders.withColumn('product_id', F.col('product_id').cast('string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6abe5c4-df5c-4526-b171-7a9324af8e3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|  min_date|  max_date|\n",
      "+----------+----------+\n",
      "|2025-07-01|2025-11-30|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check what's the maximum and minimum date\n",
    "df_orders.agg(\n",
    "    F.min(\"order_placement_date\").alias(\"min_date\"),\n",
    "    F.max(\"order_placement_date\").alias(\"max_date\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "441686d7-a434-4536-a893-7c3ad9c7f1d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Join with products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2bf5621-93c6-4085-b0d8-2311a734b484",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+-----------+----------+---------+--------------------+--------------------+---------+--------------------+\n",
      "|     order_id|order_placement_date|customer_id|product_id|order_qty|      read_timestamp|           file_name|file_size|        product_code|\n",
      "+-------------+--------------------+-----------+----------+---------+--------------------+--------------------+---------+--------------------+\n",
      "|FJUL312422401|          2025-07-10|     789422|  25891401|    406.0|2025-11-30 15:23:...|orders_2025_07_10...|    20202|da6bfc596c1360ca0...|\n",
      "|FJUL316103602|          2025-07-14|     789103|  25891403|    235.0|2025-11-30 15:23:...|orders_2025_07_14...|    20354|77b6f538a9d0e0cf8...|\n",
      "|FJUL316402601|          2025-07-14|     789402|  25891601|    167.0|2025-11-30 15:23:...|orders_2025_07_14...|    20354|716fa4e54b7894c91...|\n",
      "|FJUL320720201|          2025-07-19|     789720|  25891103|    358.0|2025-11-30 15:23:...|orders_2025_07_19...|    21044|102628255d24304d6...|\n",
      "|FJUL321403603|          2025-07-19|     789403|  25891603|    169.0|2025-11-30 15:23:...|orders_2025_07_19...|    21044|451f7167b28a25bde...|\n",
      "+-------------+--------------------+-----------+----------+---------+--------------------+--------------------+---------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_products = spark.table(\"fmcg.silver.products\")\n",
    "df_joined = df_orders.join(df_products, on=\"product_id\", how=\"inner\").select(df_orders[\"*\"], df_products[\"product_code\"])\n",
    "\n",
    "df_joined.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cee55f9-cf77-4738-8b3e-f3e1371e9187",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if not (spark.catalog.tableExists(silver_table)):\n",
    "    df_joined.write.format(\"delta\").option(\n",
    "        \"delta.enableChangeDataFeed\", \"true\"\n",
    "    ).option(\"mergeSchema\", \"true\").mode(\"overwrite\").saveAsTable(silver_table)\n",
    "else:\n",
    "    silver_delta = DeltaTable.forName(spark, silver_table)\n",
    "    silver_delta.alias(\"silver\").merge(df_joined.alias(\"bronze\"), \"silver.order_placement_date = bronze.order_placement_date AND silver.order_id = bronze.order_id AND silver.product_code = bronze.product_code AND silver.customer_id = bronze.customer_id\").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b200747-2ed1-4a68-a816-5ab00d60a117",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## GOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f63821f8-87ce-4b6c-b773-d2e068ac0674",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-------------+--------------------+----------+-------------+\n",
      "|     order_id|      date|customer_code|        product_code|product_id|sold_quantity|\n",
      "+-------------+----------+-------------+--------------------+----------+-------------+\n",
      "|FJUL312422401|2025-07-10|       789422|da6bfc596c1360ca0...|  25891401|        406.0|\n",
      "|FJUL316103602|2025-07-14|       789103|77b6f538a9d0e0cf8...|  25891403|        235.0|\n",
      "+-------------+----------+-------------+--------------------+----------+-------------+\n",
      "only showing top 2 rows\n"
     ]
    }
   ],
   "source": [
    "df_gold = spark.sql(f\"SELECT order_id, order_placement_date as date, customer_id as customer_code, product_code, product_id, order_qty as sold_quantity FROM {silver_table};\")\n",
    "\n",
    "df_gold.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f30a3f3-a9ab-4aeb-b06f-3f7f1a1119a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating New Table\n"
     ]
    }
   ],
   "source": [
    "if not (spark.catalog.tableExists(gold_table)):\n",
    "    print(\"creating New Table\")\n",
    "    df_gold.write.format(\"delta\").option(\n",
    "        \"delta.enableChangeDataFeed\", \"true\"\n",
    "    ).option(\"mergeSchema\", \"true\").mode(\"overwrite\").saveAsTable(gold_table)\n",
    "else:\n",
    "    gold_delta = DeltaTable.forName(spark, gold_table)\n",
    "    gold_delta.alias(\"source\").merge(df_gold.alias(\"gold\"), \"source.date = gold.date AND source.order_id = gold.order_id AND source.product_code = gold.product_code AND source.customer_code = gold.customer_code\").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8676858a-5c75-40ed-b1cd-24fabe60060b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Merging with Parent company\n",
    "- Note: We want data for monthly level but child data is on daily level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5997177b-d0f2-45af-9e7a-513d864b2b25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Full Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7eada1c3-bdab-45fd-9e19-bd60d466d307",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------------+-------------+\n",
      "|      date|        product_code|customer_code|sold_quantity|\n",
      "+----------+--------------------+-------------+-------------+\n",
      "|2025-07-10|da6bfc596c1360ca0...|       789422|        406.0|\n",
      "|2025-07-14|77b6f538a9d0e0cf8...|       789103|        235.0|\n",
      "|2025-07-14|716fa4e54b7894c91...|       789402|        167.0|\n",
      "|2025-07-19|102628255d24304d6...|       789720|        358.0|\n",
      "|2025-07-19|451f7167b28a25bde...|       789403|        169.0|\n",
      "|2025-07-27|e91ba9d665f90254d...|       789403|        367.0|\n",
      "|2025-08-03|d9ebd1ca64d23951a...|       789903|         59.0|\n",
      "|2025-08-03|c68834ceaff15846b...|       789303|         85.0|\n",
      "|2025-08-10|102628255d24304d6...|       789902|        436.0|\n",
      "|2025-08-14|77b6f538a9d0e0cf8...|       789402|        382.0|\n",
      "+----------+--------------------+-------------+-------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "df_child = spark.sql(f\"SELECT date, product_code, customer_code, sold_quantity FROM {gold_table}\")\n",
    "df_child.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26167c2d-01a3-47a7-ad1d-6536e452a95a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40811"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_child.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d306951-2f47-4362-88fd-9dbba218ebe7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------------------------------------------------------+-------------+-------------+\n",
      "|date      |product_code                                                    |customer_code|sold_quantity|\n",
      "+----------+----------------------------------------------------------------+-------------+-------------+\n",
      "|2025-07-01|da6bfc596c1360ca07bda4e0ae6bfe3b8456517fc6e8ddc265630ff940f9ab05|789422       |5011.0       |\n",
      "|2025-07-01|77b6f538a9d0e0cf845db5c2cbecec46fdd30303b501e06f64baf1d4dc0e66f9|789103       |5203.0       |\n",
      "|2025-07-01|716fa4e54b7894c910180276e0535d49afb25cdcfac09533fb74ae00689e5742|789402       |1726.0       |\n",
      "|2025-07-01|102628255d24304d6bbe0438b1ac992054f262e0814d306d0a34d7356cef3268|789720       |3712.0       |\n",
      "|2025-07-01|451f7167b28a25bde73995910e31c07dfa26411f1db47847f19e16747effbdaa|789403       |1816.0       |\n",
      "+----------+----------------------------------------------------------------+-------------+-------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_monthly = (\n",
    "    df_child\n",
    "    # 1. Get month start date (e.g., 2025-11-30 ‚Üí 2025-11-01)\n",
    "    .withColumn(\"month_start\", F.trunc(\"date\", \"MM\"))   # or F.date_trunc(\"month\", \"date\").cast(\"date\")\n",
    "\n",
    "    # 2.Group at monthly grain by month_start + product_code + customer_code\n",
    "    .groupBy(\"month_start\", \"product_code\", \"customer_code\")\n",
    "    .agg(\n",
    "        F.sum(\"sold_quantity\").alias(\"sold_quantity\")\n",
    "    )\n",
    "\n",
    "    # 3. Rename month_start back to `date` to match your target schema\n",
    "    .withColumnRenamed(\"month_start\", \"date\")\n",
    ")\n",
    "\n",
    "df_monthly.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d61cf21f-5766-44f1-8408-65fc0c1c2c69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3060"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_monthly.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ee32698-688c-40ec-a944-40522fae0634",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_parent_delta = DeltaTable.forName(spark, f\"{catalog}.{gold_schema}.fact_orders\")\n",
    "gold_parent_delta.alias(\"parent_gold\").merge(df_monthly.alias(\"child_gold\"), \"parent_gold.date = child_gold.date AND parent_gold.product_code = child_gold.product_code AND parent_gold.customer_code = child_gold.customer_code\").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1_full_load_fact",
   "widgets": {
    "catalog": {
     "currentValue": "fmcg",
     "nuid": "e3192861-920a-458b-aefd-45300e31924f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "fmcg",
      "label": "Catalog",
      "name": "catalog",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "fmcg",
      "label": "Catalog",
      "name": "catalog",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "data_source": {
     "currentValue": "orders",
     "nuid": "17ff9cdc-99b7-4f63-b1a0-555ddcad95b7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "orders",
      "label": "Data Source",
      "name": "data_source",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "orders",
      "label": "Data Source",
      "name": "data_source",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
